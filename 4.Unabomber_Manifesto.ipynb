{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36416a28-9ddb-40d8-b50f-391a98266765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from nltk import word_tokenize, Counter, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import requests\n",
    "wordnet_lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "ENGLISH_STOPS = set(stopwords.words('english'))\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2456001d-7e99-4076-b970-fdc549838ce9",
   "metadata": {},
   "source": [
    "#### Do not use this section more than once. The file is already saved locally as 'manifesto.txt'. #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2512818f-4326-4bfe-8425-bcceb1675b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the Washington post text of Unabomber's Manifesto\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "url = \"http://www.washingtonpost.com/wp-srv/national/longterm/unabomber/manifesto.text.htm\"\n",
    "response = urllib.request.urlopen(url)\n",
    "webContent = response.read()\n",
    "clean_text = ' '.join(BeautifulSoup(webContent, \"html.parser\").stripped_strings)\n",
    "# print(clean_text)\n",
    "\n",
    "file_WP = open('manifesto.txt', 'w')\n",
    "file_WP.write(clean_text)\n",
    "file_WP.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723494a0-b0ae-4a91-807b-47c09070dbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edbee2c9-e01c-425d-8e41-15d5e5a846ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text): # Vectorise, cahnge to smaller case,clean,and lemmatize.  \n",
    "    tokens = word_tokenize(text)\n",
    "    lower_tokens = [token.lower() for token in tokens] # lower case\n",
    "    alpha_only = [t for t in lower_tokens if t.isalpha()] #  alpha_only\n",
    "    no_stops = [t for t in alpha_only if t not in ENGLISH_STOPS]# Remove stop words\n",
    "    lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]#lemmatized\n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "def tf_idf(text):                #replaces text\n",
    "    texts = [preprocess(sentence) for sentence in sent_tokenize(text)] #Sentences sepearted \n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    tfidf = TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    tfidf_weights = {dictionary.get(id): value\n",
    "                     for doc in corpus_tfidf\n",
    "                     for id, value in doc}\n",
    "    sorted_tfidf_weights = sorted(tfidf_weights.items(), key=lambda w: w[1])\n",
    "    return sorted_tfidf_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d80141-2f0a-4602-a57c-13ab57238cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Most common words: ('society', 'system', 'people', 'power', 'would', 'one', 'human', 'technology', 'leftist', 'need', 'may', 'social', 'many', 'modern', 'freedom', 'problem', 'goal', 'paragraph', 'make', 'individual', 'way', 'industrial', 'process', 'man', 'behavior')\n",
      "\n",
      "\n",
      "\n",
      "Most popular terms: ('society', 'people', 'freedom', 'whole', 'human', 'lead', 'system', 'necessity', 'process', 'use', 'population', 'term', 'enough', 'develop', 'fact', 'thought', 'state', 'paragraph', 'increasing', 'today', 'example', 'tendency', 'study', 'person', 'needed')\n",
      "\n",
      "\n",
      "\n",
      "Most unique/important terms: ('adherent', 'happening', 'inspire', 'drawn', 'flop', 'meantime', 'gaia', 'enterprise', 'stop', 'holy', 'risk', 'fiction', 'slight', 'otherwise', 'lucky', 'license', 'simplification', 'personnel', 'carried', 'crossroad', 'eminent', 'exactly', 'paramount', 'danger', 'virtue')\n"
     ]
    }
   ],
   "source": [
    "file_WP = open('manifesto.txt', 'r')\n",
    "content = file_WP.read()\n",
    "file_WP.close\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #content = retrieve_text(\"http://www.washingtonpost.com/wp-srv/national/longterm/unabomber/manifesto.text.htm\")\n",
    "    \n",
    "    tokens = preprocess(content)\n",
    "    token_counter = Counter(tokens)\n",
    "\n",
    "    most_common = token_counter.most_common(25)\n",
    "    \n",
    "    tf_idf_results = tf_idf(content)\n",
    "    popular_terms = tf_idf_results[:25]\n",
    "    rare_terms =  tf_idf_results[-25:]\n",
    "\n",
    "    # print out words only (without counts and weights)\n",
    "    keys = lambda x: next(zip(*x))\n",
    "    print('\\n' * 2)\n",
    "    print(f\"Most common words: {keys(most_common)}\")\n",
    "    print('\\n' * 2)\n",
    "    print(f\"Most popular terms: {keys(popular_terms)}\")\n",
    "    print('\\n' * 2)\n",
    "    print(f\"Most unique/important terms: {keys(rare_terms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1bf9f5c6-f454-4d0f-8429-bfabe3bde25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Frequency Words\n",
      "       Words    TF/IDF\n",
      "0    society  0.070668\n",
      "1     people  0.093045\n",
      "2    freedom  0.094451\n",
      "3      whole  0.094847\n",
      "4      human  0.095126\n",
      "5       lead  0.098510\n",
      "6     system  0.099239\n",
      "7  necessity  0.099739\n",
      "8    process  0.101075\n",
      "9        use  0.102728\n",
      "\n",
      "\n",
      "\n",
      "Low Frequency Words\n",
      "               Words    TF/IDF\n",
      "3499         license  0.781434\n",
      "3500  simplification  0.816939\n",
      "3501       personnel  0.822237\n",
      "3502         carried  0.827271\n",
      "3503       crossroad  0.827443\n",
      "3504         eminent  0.833276\n",
      "3505         exactly  0.836579\n",
      "3506       paramount  0.860334\n",
      "3507          danger  0.871846\n",
      "3508          virtue  0.908159\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_idf_df= pd.DataFrame(tf_idf(content),columns=['Words', 'TF/IDF'])\n",
    "print (\"High Frequency Words\")\n",
    "print(tf_idf_df.head(10))\n",
    "print('\\n' * 2)\n",
    "print (\"Low Frequency Words\")\n",
    "print(tf_idf_df.tail(10))\n",
    "print('\\n' * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7993d74e-baa0-40c2-aff3-059de46b7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "input=[content]\n",
    "vectorization_result = vectorizer.fit_transform(input)\n",
    "\n",
    "vectorization_df = pd.DataFrame(\n",
    "    list(zip(vectorizer.get_feature_names(), np.ravel(article_result.sum(axis=0)))), columns=[\"Word\", \"TF-IDF\"]\n",
    ")\n",
    "\n",
    "vectorization_df = article_df.sort_values(by=[\"TF-IDF\"], ascending=False)\n",
    "vectorization_df = article_df[article_df['TF-IDF'] > 0.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21130b89-fbd4-47d3-b5b4-b95ce2f8bda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Frequency Words\n",
      "            Word  TF-IDF\n",
      "3449     society     244\n",
      "2742      people     222\n",
      "2841       power     167\n",
      "1916       human     140\n",
      "3674  technology     127\n",
      "3439      social      98\n",
      "2045  industrial      97\n",
      "2453      modern      94\n",
      "1690     freedom      90\n",
      "2912     process      73\n",
      "\n",
      "\n",
      "\n",
      "Low Frequency Words\n",
      "                    Word  TF-IDF\n",
      "2682               owner       1\n",
      "2681               owing       1\n",
      "1077           deceiving       1\n",
      "2679         overwhelmed       1\n",
      "2678            overtime       1\n",
      "635                breed       1\n",
      "1726                 gas       1\n",
      "637               bridge       1\n",
      "2674  oversimplification       1\n",
      "2673           oversight       1\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"High Frequency Words\")\n",
    "print(vectorization_df.head(10))\n",
    "print('\\n' * 2)\n",
    "print (\"Low Frequency Words\")\n",
    "print(vectorization_df.tail(10))\n",
    "print('\\n' * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f933fb-c92d-4349-b19f-a73f4046502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72029dc2-067b-4733-af1e-66aa6c19ad23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e61e7e-2646-443f-ae0a-a4ed31353a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c09e0a-b73b-4b0f-a587-25e96781bb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097cedb-5f0b-4ccb-b5a9-b4de5e5ec4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf414b9-0680-4171-b1fb-8b8f7e60e921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
